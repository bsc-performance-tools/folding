
\chapter{Tool design}

While the end user executes a single command to apply the \FOLDING tool, this command hides two major components that are executed sequentially and all the outputs are generated into a newly created directory with the name of the input trace-file.
The first component processes a user-given trace-file that contains instrumented and sampled data and generates a textual file that contains sequences of instances and samples.
The second component takes these sequences of instances and samples, then applies the contouring algorithm, any performance model, and the call-stack processing, and, finally, it generates the output results.
Both components are grouped together within the \texttt{folding.sh} appearing to the user that the \FOLDING simply consists of a single tool.
The tool package contains additional components that may be capture the interest of the user.

\section{First component: trace-file processing}

\input{figures/user-guide/codeblocks-fuse-extract.tex}

The first component is divided into three phases that are executed one after another with the user-given trace-file and each of these parse the given trace-file and generates another trace-file that will be used in the subsequent phase as depicted in Figure~\ref{fig:dataflow_1st_component_folding}.
Each of these phases are built in a similar fashion.
They parse the input trace-file and keep in memory information regarding the thread state, and eventually, add information to the output.
The phases are:

\begin{enumerate}

	\item \texttt{codeblocks} (found in \texttt{src/codeblocks})\\
	This phase attributes to each sample information regarding to the loop / code region that it belongs to according to the application source code. 

	\item \texttt{fuse} (found in \texttt{src/fuse})\\
	This phase compacts the trace-file and ensures that the resulting trace-file is well formed.

	\item \texttt{extract} (found in \texttt{src/extract})\\
	This is the final phase and extracts information regarding the instances and samples within the trace-file.

\end{enumerate}

The output of this component is a set of files containing information relative to the application. 
The most notable output is the \texttt{.extract} file, which contains the sequence of instances and their samples.
For instance, Listing~\ref{lst:ExampleGenerationInterpolationOutput} shows the contents of the \texttt{.extract} file generated using the provided example to demonstrate the API facility.
This listing contains information regarding one instance of the \texttt{FunctionA} region.
The instance starts at timestamp 1,000~ns and lasts 4,500~ns, and it executes up to 2,500 instructions (PAPI\_TOT\_INS) and takes 5,000 cycles (PAPI\_TOT\_CYC) to complete.
This instance has two samples associated that ocurred at timestamps 2,000 and 4,000, and each of those provides information regarding the aforementioned performance counters.

\input{listings/user-guide/folding-writer-out.tex}

\section{Second component: applying the folding}

The main objective of this component relies on processing the instances and samples extracted and generate the output results.
These results include the temporal evolution of the performance counters, any models requested by the user, the source code references and memory references progression, and the results are written in gnuplot and \PARAVER trace files.
This section gives a summarized view of the folding work-flow by depicting the most notable class diagrams found in the application source code.

\input{figures/user-guide/tool-design-interpolate-instances.tex}

Figure~\ref{fig:tool_design_interpolate_instances} shows a portion of the classes that are most important within this tool.
The classes \textsl{Instance} and \textsl{Sample} refer to the instances and samples as-is, without any further processing and as generated by the \texttt{extract} tool, in which each \textsl{Instance} contains a set of \textsl{Sample}, and every \textsl{Instance} belongs to an \textsl{InstanceContainer}.

\input{figures/user-guide/tool-design-interpolate-instance-separator.tex}

After reading every \textsl{Instance}, the folding may apply a clustering algorithm (see Figure~\ref{fig:tool_design_interpolate_instance_separator}) according to the duration of each instance in order to reduce the difference between folded \textsl{Instance}.
Currently, there are three alternatives regarding the grouping.

\begin{itemize}

	\item \textsl{InstanceSeparatorNone} groups all instances into a single group.

	\item \textsl{InstanceSeparatorAuto} automatically groups the instances according to their duration. The grouping partitions the time-space interval defined by the shortest and longest instances and looks for group of nearby instances.

	\item \textsl{InstanceSeparatorDBSCAN} groups the instances according to a DBSCAN algorithm applied to the duration of the instances. The DBSCAN algorithm groups together instances that are closely packed together (instances with many nearby neighbors) in terms of time and marks as outliers those instances that lie alone in low-density regions. This grouping uses the ClusteringSuite implementation from the BSC performance tools\footnote{See \url{http://www.bsc.es/computer-sciences/performance-tools/downloads}.}.

\end{itemize}

This grouping begets the \textsl{InstanceGroup} objects which contains references to those \textsl{Instance} that belong to that particular group.
Then, the folding removes the outliers to each \textsl{Instance} within every \textsl{InstanceGroup} and store the outliers and the remaining in the \textit{excluded} and \textit{instances} associations, respectively.

\input{figures/user-guide/tool-design-interpolate-sample-selector.tex}

Since the complexity of the contouring algorithms depends on the number of points to connect, and therefore the number of samples to fold, the \FOLDING tool supports limiting the number of samples given to these algorithms.
Figure~\ref{fig:tool_design_interpolate_sample_selector} depicts the class diagram of the available \textsl{SampleSelector} mechanisms to limit the number of samples.

\begin{itemize}

	\item \textsl{SampleSelectorDefault} the \textit{select} method returns all of the samples within the \textsl{InstanceGroup}. This is useful when the user does not impose any limit to the number of samples to be folded.

	\item \textsl{SampleSelectorFirst} receives a threshold ($N$) in the class constructor. Then, the \textit{select} method tags the first $N$ samples for the processing while the rest are marked as \textit{unused}.

	\item \textsl{SampleSelectorDistance} receives a threshold ($N$) in the class constructor. Then, the \textit{select} method tags $N$ samples that are equidistant within the \textsl{Instance} duration, while the rest are \textit{unused}.

\end{itemize}

\input{figures/user-guide/tool-design-interpolate-interpolation.tex}

Then the \FOLDING repeatedly applies the contouring algorithm to the \textit{used} samples among the different \textsl{InstanceGroup} objects.
The contouring algorithm applies to each performance counter individually, and as of writing this document, there are two approaches that honor the \textsl{Interpolation} super-class virtual method (mainly \texttt{do\_interpolate}):

\begin{itemize}

	\item \textsl{InterpolationKriger} uses the self-provided contouring algorithm based on the Kriging mechanism to implement the \texttt{do\_interpolate}.

	\item \textsl{InterpolationRstrucchange} employs the strucchange package\footnote{\url{http://cran.r-project.org/web/packages/strucchange/index.html}} from the R statistical package\footnote{\url{http://www.r-project.org}} to use piece-wise linear regressions to the folded samples. Additionally, this package may benefit from parallel environments if the doParallel package\footnote{\url{http://cran.r-project.org/package=doParallel}} is available on the system.

\end{itemize}

The interpolation results are stored, per performance counter, into \textsl{InterpolationResults} objects that are associated by \textsl{InstanceGroup} by the attribute \textit{interpolated} (as depicted in Figure~\ref{fig:tool_design_interpolate_instances}).
The \textit{interpolated} attribute is implemented as a hash function indexed by the performance counter, so that the interpolation results can be fetched easily.

\input{figures/user-guide/tool-design-interpolate-model.tex}

\input{XML/folding-model-example.tex}

The \FOLDING allows defining performance models based on performance counters using XML files (see Listing~\ref{lst:Folding_sample_model} for exemplification purposes and \texttt{\$\{FOLDING\_HOME\}/etc/models} for more detailed examples).
Within every XML there may be one or several components (in the last Listing these are: \texttt{l1\_dcm\_ratio}, \texttt{l2\_dcm\_ratio} and \texttt{mips}) that will be later represented in the resulting gnuplot using the selected colors and Y-axis (left [y1] or right [y2]).
Each component may refer to the instantaneous value of a certain performance counter (as in the \texttt{mips} component), a constant value or the operation (addition, subtraction, multiplication and division) between two other values (as in \texttt{l1\_dcm\_ratio} and \texttt{l2\_dcm\_ratio} components).
The \FOLDING implements the performance models based on performance counters employing the diagram classes show in Figure~\ref{fig:tool_design_interpolate_model}.
The XML model files are loaded into the \textsl{Model} class and each of them may contain multiple components (\textsl{ComponentModel}).
The \textsl{ComponentModel} implements the definition of the component on top of the \textsl{ComponentNode} derived sub-classes.
These sub-classes allow referencing constant values (\textsl{ComponentNode\_constant}), interpolated results from a specific performance counter (\textsl{ComponentNode\_data}) and operation between other two \textsl{ComponentNode} objects).

\input{figures/user-guide/tool-design-interpolate-callstack-processor.tex}

With respect to the analysis of the call-stack, the \FOLDING tool has implemented this analysis through the \textsl{CallstackProcessor} related-classes that receives a set of \textsl{Sample} objects to explore.
Currently, the unique implementation available relies on aligning the call-stacks from the given samples and then exploring the call-stack frames at a given level whether consecutive samples refer to the same routine.
If the number of samples surpasses a given threshold, then applies it recursively to the next level until no more levels are available or the number of samples do not surpass the threshold.
